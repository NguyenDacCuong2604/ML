{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NguyenDacCuong2604/ML/blob/main/Lab_4_20130215_NguyenDacCuong.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to continous dealing with **Logistic Regression**, **kNN**, and **Decision Tree** alogirthms applied to classification tasks. \n",
        "\n",
        "*   **Deadline: 23:59, 12/03/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. \n",
        "Apply **LogisticRegression** to iris dataset which aims at classifying species of iris based on sepal_length (chiều dài đài hoa), sepal_width, petal_length (chiều dài cánh hoa), petal_width. The species are '**setosa**' '**versicolor**' and '**virginica**'. \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from sklearn import datasets\n",
        "data4 = datasets.load_iris()\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "#Load the iris dataset\n",
        "iris = load_iris()\n",
        "#Split the dataset 70%-30%\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=0)\n",
        "#Regression model\n",
        "model = LogisticRegression()\n",
        "#Train the model\n",
        "model.fit(X_train, y_train)\n",
        "#Testing set\n",
        "y_pred = model.predict(X_test)\n",
        "#Accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "#Do chinh xac cua mo hinh\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e945141-aacd-454f-cdae-a00901d99bef"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "Apply LogisticRegression to **MNIST** dataset (mnist.csv) which aims at classifying handwritten digits. Dataset includes 784 pixels values of images (28x28). \n",
        "\n",
        "\n",
        "```\n",
        "from sklearn import datasets\n",
        "# load the MNIST digits dataset\n",
        "mnist = datasets.load_digits()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "S43IoUT-0OQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "pl1cr7XV2rEc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "#load data\n",
        "mnist = datasets.load_digits()\n",
        "#split khong can\n",
        "#create Regression model\n",
        "model = LogisticRegression(max_iter=2000)\n",
        "#train model\n",
        "model.fit(mnist.data, mnist.target)\n",
        "#test\n",
        "y_pred = model.predict(mnist.data)\n",
        "#accuracy\n",
        "accuracy = accuracy_score(mnist.target, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "_xhPpF5b033h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8965aa4c-ff1b-4a7b-a536-ce123582983b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "Apply another classification algorithm named kNN, which is an instance classifcation model. \n",
        "*  3.1. Perform kNN algorithm to Iris dataset with k={1, 3, 5, …, 29}. Select the best value of k.\n",
        "\n",
        "*   3.2. Then compare the obtained results with those using Logistic regression (based on metrics: accuracy, precision, recall, f1 measure).\n"
      ],
      "metadata": {
        "id": "Rti2y0Wz2KY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "tj5Cp-eC6lVz"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "#load dataset\n",
        "iris = load_iris()\n",
        "#split 7-3\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n",
        "metrics_dict = {'k':[], 'accuracy':[], 'precision':[], 'recall':[], 'f1':[]}\n",
        "#k values\n",
        "for k in range(1, 30, 2):\n",
        "    # Create a kNN\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    # Train the kNN \n",
        "    knn.fit(X_train, y_train)\n",
        "    # Test\n",
        "    y_pred = knn.predict(X_test)  \n",
        "    #metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='macro')\n",
        "    recall = recall_score(y_test, y_pred, average='macro')\n",
        "    f1 = f1_score(y_test, y_pred, average='macro') \n",
        "    # Store the performance metrics\n",
        "    metrics_dict['k'].append(k)\n",
        "    metrics_dict['accuracy'].append(accuracy)\n",
        "    metrics_dict['precision'].append(precision)\n",
        "    metrics_dict['recall'].append(recall)\n",
        "    metrics_dict['f1'].append(f1)  \n",
        "# Print\n",
        "print(\"k\\tAccuracy\\tPrecision\\tRecall\\t\\tF1\")\n",
        "for i in range(len(metrics_dict['k'])):\n",
        "    print(\"{}\\t{:.4f}\\t\\t{:.4f}\\t\\t{:.4f}\\t\\t{:.4f}\".format(\n",
        "        metrics_dict['k'][i], metrics_dict['accuracy'][i], metrics_dict['precision'][i], metrics_dict['recall'][i], metrics_dict['f1'][i]\n",
        "    ))\n"
      ],
      "metadata": {
        "id": "13LkkfpS2ZUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b050e1f-92c6-46fc-f42c-e2b8d7f391c0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k\tAccuracy\tPrecision\tRecall\t\tF1\n",
            "1\t1.0000\t\t1.0000\t\t1.0000\t\t1.0000\n",
            "3\t1.0000\t\t1.0000\t\t1.0000\t\t1.0000\n",
            "5\t1.0000\t\t1.0000\t\t1.0000\t\t1.0000\n",
            "7\t1.0000\t\t1.0000\t\t1.0000\t\t1.0000\n",
            "9\t1.0000\t\t1.0000\t\t1.0000\t\t1.0000\n",
            "11\t1.0000\t\t1.0000\t\t1.0000\t\t1.0000\n",
            "13\t1.0000\t\t1.0000\t\t1.0000\t\t1.0000\n",
            "15\t1.0000\t\t1.0000\t\t1.0000\t\t1.0000\n",
            "17\t1.0000\t\t1.0000\t\t1.0000\t\t1.0000\n",
            "19\t1.0000\t\t1.0000\t\t1.0000\t\t1.0000\n",
            "21\t1.0000\t\t1.0000\t\t1.0000\t\t1.0000\n",
            "23\t1.0000\t\t1.0000\t\t1.0000\t\t1.0000\n",
            "25\t1.0000\t\t1.0000\t\t1.0000\t\t1.0000\n",
            "27\t1.0000\t\t1.0000\t\t1.0000\t\t1.0000\n",
            "29\t1.0000\t\t1.0000\t\t1.0000\t\t1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. \n",
        "Similar to Task 3, apply kNN algorithm to **mnist** dataset which included in datasets of sklearn API.\n",
        "*  4.1.\tPerform kNN algorithm to Iris dataset with k={1, 3, 5, …, 29}. Select the best value of k.\n",
        "*  4.2.\tThen compare the obtained results with those using Logistic regression (based on metrics: accuracy, precision, recall, f1 measure).\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "HjRarsAy8Q1s"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "#load\n",
        "mnist = load_digits()\n",
        "X = mnist.data\n",
        "y = mnist.target\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "# Split 7-3\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "# values from 1 to 29\n",
        "k_values = range(1, 30, 2) \n",
        "accuracy_scores = []\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "best_k = k_values[accuracy_scores.index(max(accuracy_scores))]\n",
        "print(\"Best k:\", best_k)\n",
        "# kNN with the best k value\n",
        "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "# Logistic Regression\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred_logreg = logreg.predict(X_test)\n",
        "# Calculate metrics for kNN and Logistic Regression\n",
        "metrics_dict = {\n",
        "    \"kNN\": {\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred_knn),\n",
        "        \"precision\": precision_score(y_test, y_pred_knn, average='weighted'),\n",
        "        \"recall\": recall_score(y_test, y_pred_knn, average='weighted'),\n",
        "        \"f1_score\": f1_score(y_test, y_pred_knn, average='weighted')\n",
        "    },\n",
        "    \"Logistic Regression\": {\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred_logreg),\n",
        "        \"precision\": precision_score(y_test, y_pred_logreg, average='weighted'),\n",
        "        \"recall\": recall_score(y_test, y_pred_logreg, average='weighted'),\n",
        "        \"f1_score\": f1_score(y_test, y_pred_logreg, average='weighted')\n",
        "    }\n",
        "}\n",
        "#print\n",
        "print(metrics_dict)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rw_-8FIf2KxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ef9841-59b5-44fb-a991-1ec515da4f5b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best k: 7\n",
            "{'kNN': {'accuracy': 0.9796296296296296, 'precision': 0.9797167935613343, 'recall': 0.9796296296296296, 'f1_score': 0.9795545648741257}, 'Logistic Regression': {'accuracy': 0.9703703703703703, 'precision': 0.971507157867087, 'recall': 0.9703703703703703, 'f1_score': 0.9705077874984867}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 5. \n",
        "Compare the performance of selected classification algorithms (**Decision Treen, kNN, and Logistic Regression**) to ***spam detection***. The dataset can be accessed from the link: http://archive.ics.uci.edu/ml/datasets/Spambase \n",
        "Attribute Information:\n",
        "The last column of 'spambase.csv denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail. The run-length attributes (55-57) measure the length of sequences of consecutive capital letters. For the statistical measures of each attribute, see the end of this file. Here are the definitions of the attributes: \n",
        "*  48 continuous real [0,100] attributes of type word_freq_WORD \n",
        "= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail. A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string. **Example**: word_freq_address: percentage of words in the e-mail that match ADDRESS.\n",
        "*  6 continuous real [0,100] attributes of type char_freq_CHAR] \n",
        "= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n",
        "*  1 continuous real [1,...] attribute of type capital_run_length_average \n",
        "= average length of uninterrupted sequences of capital letters\n",
        "*  1 continuous integer [1,...] attribute of type capital_run_length_longest \n",
        "= length of longest uninterrupted sequence of capital letters\n",
        "*  1 continuous integer [1,...] attribute of type capital_run_length_total = sum of length of uninterrupted sequences of capital letters = total number of capital letters in the e-mail\n",
        "*  1 nominal {0,1} class attribute of type spam = denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In order to compare the performance of selected algorithms, some common metrics including **accuracy, precision, recall, f1 measures** could be used.\n"
      ],
      "metadata": {
        "id": "MVzSk4l505E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code"
      ],
      "metadata": {
        "id": "W_1v_ivR2f6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}